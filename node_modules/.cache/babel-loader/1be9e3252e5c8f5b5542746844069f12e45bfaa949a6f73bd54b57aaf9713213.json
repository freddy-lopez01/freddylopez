{"ast":null,"code":"import React from'react';import'./MachineLearning.css';import{jsx as _jsx,jsxs as _jsxs}from\"react/jsx-runtime\";const MachineLearning=()=>{return/*#__PURE__*/_jsxs(\"div\",{className:\"machine-main\",children:[/*#__PURE__*/_jsx(\"h1\",{className:\"ml-projects\",children:\"Machine Learning Projects\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"project-list\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"p-1\",children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Disease-Symptom Classifier\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"proj-info\",children:[/*#__PURE__*/_jsx(\"img\",{src:\"disease.png\",alt:\"CNN for MNIST\",className:\"project-image\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"about-section\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Overview\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"This project implements a machine learning model to predict diseases based on symptoms using a Decision Tree Classifier. The model is trained on a dataset containing symptom severity weights and their associated diseases. The primary objective is to predict the correct disease based on input symptoms and analyze the performance of the model with different hyperparameters. The final overall accuracy of the model was 99% with an average F-1 score of the model being 99% as well. Due to the small nature of the dataset and the decision tree performed exceptionally well.\"}),/*#__PURE__*/_jsx(\"h3\",{children:\"Dataset Files\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"Symptom-severity.csv: Symptom severity weights.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"reformated_dataset.csv: Reformatted dataset for training.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"symptom_precaution.csv: Precautions associated with each disease.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"symptom_Description.csv: Descriptions of each disease.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"decision_tree.png: Visualization of the trained decision tree.\"})]})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"p-2\",children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Poisonous Mushroom Classifier\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"proj-info\",children:[/*#__PURE__*/_jsx(\"img\",{src:\"mushroom.jpeg\",alt:\"CNN for MNIST\",className:\"project-image\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"about-section\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Overview\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"This model was trained utilizing a decision tree model and did NOT utilize libraries such as ScikitLearn, Pytorch, or Tensorflow. The funcitons for determiing the best feature to split on, entropy, info gain, etc, were implemented by hand. Both Perceptron and Logistic Regression algotrithms were implemented to compare which performed better. I began by loading the data from a file and then compute the sigmoid activation for inputs. I trainedc the logistic regression model using batch gradient descent, where I initialize weights and bias, update them iteratively based on gradients, and apply L2 regularization. After training, I use the model to predict the probability of the positive class for new input features. Finally, I manage the entire workflow, from data loading and model training to evaluating its accuracy on a test set and reporting the results.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"The final accuracy for this model resulted in a 98% accuracy.\"}),/*#__PURE__*/_jsx(\"h3\",{children:\"Dataset Files\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"agaricuslepiotatrain1.csv: Training data of 6000 different mushroom specimins with 17 features\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"agaricuslepiotatest1.csv: Testing data of 2126 different mushroom specimins with 17 features and target feature\"})]})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"p-3\",children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Convolutional Neural Network (CNN) for MNIST Classification \"}),/*#__PURE__*/_jsxs(\"div\",{className:\"proj-info\",children:[/*#__PURE__*/_jsx(\"img\",{src:\"Mnist.png\",alt:\"CNN for MNIST\",className:\"project-image\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"about-section\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Overview\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"This project implements a Convolutional Neural Network (CNN) using PyTorch to classify handwritten digits from the MNIST dataset. The model is trained to recognize numbers from 0 to 9 based on the pixel values of 28x28 grayscale images.The model is trained for 10 epochs with a batch size of 100. During training, the average loss and accuracy are computed for both the training and test sets.\"}),/*#__PURE__*/_jsx(\"p\",{className:\"desc\",children:\"After training the model over 11 epochs, the model reulted in having a maximum accuracy of 98% and training accuracy of about 93%. The overall loss during training was around 0.0155 over 10 epochs. Testing overall loss was less than 0.0150 over 10 epochs.\"}),/*#__PURE__*/_jsx(\"h3\",{children:\"Dataset Files\"})]})]})]})]})]});};export default MachineLearning;","map":{"version":3,"names":["React","jsx","_jsx","jsxs","_jsxs","MachineLearning","className","children","src","alt"],"sources":["/Users/freddylopez/Documents/Projects/PersonalSite/revamped/src/components/MachineLearning.jsx"],"sourcesContent":["import React from 'react';\nimport './MachineLearning.css';\n\n\nconst MachineLearning = () => {\n  return (\n    <div className=\"machine-main\">\n      <h1 className=\"ml-projects\">Machine Learning Projects</h1>\n      <div className=\"project-list\">\n        <div className=\"p-1\">\n          <h2>Disease-Symptom Classifier</h2>\n          <div className=\"proj-info\">\n            <img src=\"disease.png\" alt=\"CNN for MNIST\" className=\"project-image\" />\n            <div className=\"about-section\">\n              <h3>Overview</h3>\n              <p className=\"desc\">This project implements a machine learning model to predict diseases based on \n                symptoms using a Decision Tree Classifier. The model is trained on a dataset containing \n                symptom severity weights and their associated diseases. The primary objective is to predict \n                the correct disease based on input symptoms and analyze the performance of the model with different hyperparameters.\n                The final overall accuracy of the model was 99% with an average F-1 score of the model being 99% as well. Due to the \n                small nature of the dataset and the decision tree performed exceptionally well.\n              </p>\n              <h3>Dataset Files</h3>\n              <p className=\"desc\">Symptom-severity.csv: Symptom severity weights.</p>\n              <p className=\"desc\">reformated_dataset.csv: Reformatted dataset for training.</p>\n              <p className=\"desc\">symptom_precaution.csv: Precautions associated with each disease.</p>\n              <p className=\"desc\">symptom_Description.csv: Descriptions of each disease.</p>\n              <p className=\"desc\">decision_tree.png: Visualization of the trained decision tree.</p>\n            </div>\n          </div>\n        </div>\n        <div className=\"p-2\">\n          <h2>Poisonous Mushroom Classifier</h2>\n          <div className=\"proj-info\">\n            <img src=\"mushroom.jpeg\" alt=\"CNN for MNIST\" className=\"project-image\" />\n            <div className=\"about-section\">\n              <h3>Overview</h3>\n              <p className=\"desc\">This model was trained utilizing a decision tree model and did NOT utilize libraries such as ScikitLearn, \n                Pytorch, or Tensorflow. The funcitons for determiing the best feature to split on, entropy, info gain, etc, were implemented by hand. \n                Both Perceptron and Logistic Regression algotrithms were implemented to compare which performed better. \n                I began by loading the data from a file and then compute the sigmoid activation for inputs. I trainedc the logistic \n                regression model using batch gradient descent, where I initialize weights and bias, update them iteratively based on \n                gradients, and apply L2 regularization. After training, I use the model to predict the probability of the positive class \n                for new input features. Finally, I manage the entire workflow, from data loading and model training to evaluating its \n                accuracy on a test set and reporting the results.</p>\n              <p className=\"desc\">The final accuracy for this model resulted in a 98% accuracy.</p>\n              <h3>Dataset Files</h3>\n              <p className=\"desc\">agaricuslepiotatrain1.csv: Training data of 6000 different mushroom specimins with 17 features</p>\n              <p className=\"desc\">agaricuslepiotatest1.csv: Testing data of 2126 different mushroom specimins with 17 features and target feature</p>\n            </div>\n          </div>\n        </div>\n        <div className=\"p-3\">\n          <h2>Convolutional Neural Network (CNN) for MNIST Classification </h2>\n            <div className=\"proj-info\">\n            <img src=\"Mnist.png\" alt=\"CNN for MNIST\" className=\"project-image\" />\n            <div className=\"about-section\">\n              <h3>Overview</h3>\n              <p className=\"desc\">This project implements a Convolutional Neural Network (CNN) using PyTorch to classify handwritten digits \n                from the MNIST dataset. The model is trained to recognize numbers from 0 to 9 based on the pixel values of 28x28 grayscale \n                images.The model is trained for 10 epochs with a batch size of 100. During training, the average loss and accuracy are computed \n                for both the training and test sets.</p>\n              <p className=\"desc\">After training the model over 11 epochs, the model reulted in having a maximum accuracy of 98% and training \n                accuracy of about 93%. The overall loss during training was around 0.0155 over 10 epochs. Testing overall loss was less than \n                0.0150 over 10 epochs.</p>\n              <h3>Dataset Files</h3>\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default MachineLearning;\n"],"mappings":"AAAA,MAAO,CAAAA,KAAK,KAAM,OAAO,CACzB,MAAO,uBAAuB,CAAC,OAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,yBAG/B,KAAM,CAAAC,eAAe,CAAGA,CAAA,GAAM,CAC5B,mBACED,KAAA,QAAKE,SAAS,CAAC,cAAc,CAAAC,QAAA,eAC3BL,IAAA,OAAII,SAAS,CAAC,aAAa,CAAAC,QAAA,CAAC,2BAAyB,CAAI,CAAC,cAC1DH,KAAA,QAAKE,SAAS,CAAC,cAAc,CAAAC,QAAA,eAC3BH,KAAA,QAAKE,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBL,IAAA,OAAAK,QAAA,CAAI,4BAA0B,CAAI,CAAC,cACnCH,KAAA,QAAKE,SAAS,CAAC,WAAW,CAAAC,QAAA,eACxBL,IAAA,QAAKM,GAAG,CAAC,aAAa,CAACC,GAAG,CAAC,eAAe,CAACH,SAAS,CAAC,eAAe,CAAE,CAAC,cACvEF,KAAA,QAAKE,SAAS,CAAC,eAAe,CAAAC,QAAA,eAC5BL,IAAA,OAAAK,QAAA,CAAI,UAAQ,CAAI,CAAC,cACjBL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,6jBAMpB,CAAG,CAAC,cACJL,IAAA,OAAAK,QAAA,CAAI,eAAa,CAAI,CAAC,cACtBL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,iDAA+C,CAAG,CAAC,cACvEL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,2DAAyD,CAAG,CAAC,cACjFL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,mEAAiE,CAAG,CAAC,cACzFL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,wDAAsD,CAAG,CAAC,cAC9EL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,gEAA8D,CAAG,CAAC,EACnF,CAAC,EACH,CAAC,EACH,CAAC,cACNH,KAAA,QAAKE,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBL,IAAA,OAAAK,QAAA,CAAI,+BAA6B,CAAI,CAAC,cACtCH,KAAA,QAAKE,SAAS,CAAC,WAAW,CAAAC,QAAA,eACxBL,IAAA,QAAKM,GAAG,CAAC,eAAe,CAACC,GAAG,CAAC,eAAe,CAACH,SAAS,CAAC,eAAe,CAAE,CAAC,cACzEF,KAAA,QAAKE,SAAS,CAAC,eAAe,CAAAC,QAAA,eAC5BL,IAAA,OAAAK,QAAA,CAAI,UAAQ,CAAI,CAAC,cACjBL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,m2BAO+B,CAAG,CAAC,cACvDL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,+DAA6D,CAAG,CAAC,cACrFL,IAAA,OAAAK,QAAA,CAAI,eAAa,CAAI,CAAC,cACtBL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,gGAA8F,CAAG,CAAC,cACtHL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,iHAA+G,CAAG,CAAC,EACpI,CAAC,EACH,CAAC,EACH,CAAC,cACNH,KAAA,QAAKE,SAAS,CAAC,KAAK,CAAAC,QAAA,eAClBL,IAAA,OAAAK,QAAA,CAAI,8DAA4D,CAAI,CAAC,cACnEH,KAAA,QAAKE,SAAS,CAAC,WAAW,CAAAC,QAAA,eAC1BL,IAAA,QAAKM,GAAG,CAAC,WAAW,CAACC,GAAG,CAAC,eAAe,CAACH,SAAS,CAAC,eAAe,CAAE,CAAC,cACrEF,KAAA,QAAKE,SAAS,CAAC,eAAe,CAAAC,QAAA,eAC5BL,IAAA,OAAAK,QAAA,CAAI,UAAQ,CAAI,CAAC,cACjBL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,2YAGkB,CAAG,CAAC,cAC1CL,IAAA,MAAGI,SAAS,CAAC,MAAM,CAAAC,QAAA,CAAC,iQAEI,CAAG,CAAC,cAC5BL,IAAA,OAAAK,QAAA,CAAI,eAAa,CAAI,CAAC,EACnB,CAAC,EACH,CAAC,EACH,CAAC,EACH,CAAC,EACH,CAAC,CAEV,CAAC,CAED,cAAe,CAAAF,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}